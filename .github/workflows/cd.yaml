name: Continuous Deployment

on:
  workflow_dispatch:
  workflow_run:
    workflows: ["Infrastructure Deployment Pipeline"]
    types:
      - completed
    branches: [ main ]

env:
  AWS_REGION: ca-central-1
  IMAGE_TAG: latest

jobs:
  build-and-push:
    name: Build & Push Images
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    outputs:
      spark-image: ${{ steps.images.outputs.spark-image }}
      backend-image: ${{ steps.images.outputs.backend-image }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Cache pip
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('data-pipeline/requirements.txt', 'app/requirements.txt') }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install -r data-pipeline/requirements.txt
          pip install -r app/requirements.txt

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v1
        with:
          mask-password: true

      - name: Build and Push Spark ETL Docker image
        run: |
          ECR_SPARK_URI=${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/spark-etl:${{ env.IMAGE_TAG }}
          docker buildx build \
            --platform linux/amd64 \
            -t $ECR_SPARK_URI \
            -f data-pipeline/docker/Dockerfile \
            --push \
            data-pipeline

      - name: Build and Push Backend Docker image
        run: |
          ECR_BACKEND_URI=${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/genai-app:${{ env.IMAGE_TAG }}
          docker buildx build \
            --platform linux/amd64 \
            -t $ECR_BACKEND_URI \
            -f app/Dockerfile \
            --push \
            app

      - name: Set image outputs
        id: images
        run: |
          echo "spark-image=${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/spark-etl:${{ env.IMAGE_TAG }}" >> $GITHUB_OUTPUT
          echo "backend-image=${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/genai-app:${{ env.IMAGE_TAG }}" >> $GITHUB_OUTPUT

  deploy-dags:
    name: Deploy DAGs to MWAA
    runs-on: ubuntu-latest
    needs: build-and-push
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Sync DAGs to S3
        run: |
          aws s3 sync data-pipeline/dags s3://${{ secrets.MWAA_DAGS_BUCKET }}/dags \
            --delete

  deploy-helm:
    name: Deploy Applications with Helm
    runs-on: ubuntu-latest
    needs: [build-and-push, deploy-dags]
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'latest'

      - name: Install Helm
        uses: azure/setup-helm@v4
        with:
          version: 'latest'

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig \
            --name ${{ secrets.EKS_CLUSTER_NAME }} \
            --region ${{ env.AWS_REGION }}

      - name: Get Terraform outputs
        id: terraform-outputs
        run: |
          # Download terraform outputs from infrastructure workflow
          if [ "${{ github.event_name }}" = "workflow_run" ]; then
            # Get the terraform outputs from the infrastructure workflow that triggered this
            echo "Fetching Terraform outputs from infrastructure workflow..."
            
            # For now, use the workflow inputs/secrets until we implement artifact download
            # TODO: Implement proper artifact download from infrastructure workflow
            echo "eks-cluster-name=${{ secrets.EKS_CLUSTER_NAME }}" >> $GITHUB_OUTPUT
            echo "dags-bucket=${{ secrets.MWAA_DAGS_BUCKET }}" >> $GITHUB_OUTPUT
            echo "aws-account-id=${{ secrets.AWS_ACCOUNT_ID }}" >> $GITHUB_OUTPUT
            echo "data-bucket=${{ secrets.DATA_BUCKET_NAME }}" >> $GITHUB_OUTPUT
          else
            # Manual dispatch - use secrets as fallback
            echo "eks-cluster-name=${{ secrets.EKS_CLUSTER_NAME }}" >> $GITHUB_OUTPUT
            echo "dags-bucket=${{ secrets.MWAA_DAGS_BUCKET }}" >> $GITHUB_OUTPUT
            echo "aws-account-id=${{ secrets.AWS_ACCOUNT_ID }}" >> $GITHUB_OUTPUT
            echo "data-bucket=${{ secrets.DATA_BUCKET_NAME }}" >> $GITHUB_OUTPUT
          fi

      - name: Deploy with Helm
        run: |
          helm upgrade --install genai-system ./helm \
            --set backend.image="${{ needs.build-and-push.outputs.backend-image }}" \
            --set sparkJob.image="${{ needs.build-and-push.outputs.spark-image }}" \
            --set cluster.name="${{ steps.terraform-outputs.outputs.eks-cluster-name }}" \
            --set cluster.region="${{ env.AWS_REGION }}" \
            --set aws.region="${{ env.AWS_REGION }}" \
            --set aws.accountId="${{ steps.terraform-outputs.outputs.aws-account-id }}" \
            --set storage.dagsBucket="${{ steps.terraform-outputs.outputs.dags-bucket }}" \
            --set storage.dataBucket="${{ steps.terraform-outputs.outputs.data-bucket }}" \
            --set-string secrets.openaiApiKey="${{ secrets.OPENAI_API_KEY }}" \
            --set-string secrets.awsAccessKeyId="${{ secrets.AWS_ACCESS_KEY_ID }}" \
            --set-string secrets.awsSecretAccessKey="${{ secrets.AWS_SECRET_ACCESS_KEY }}" \
            --namespace genai-system \
            --create-namespace \
            --wait \
            --timeout=10m

      - name: Verify deployment
        run: |
          kubectl get pods -n genai-system
          kubectl get services -n genai-system
