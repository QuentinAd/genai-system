version: '3.8'

services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres_data:/var/lib/postgresql/data

  airflow-init:
    image: apache/airflow:2.8.1-python3.10
    depends_on:
      - postgres
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__FERNET_KEY: ${FERNET_KEY}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: ${AIRFLOW__CORE__SQL_ALCHEMY_CONN}
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./spark_jobs:/opt/airflow/spark_jobs
      - ./data:/opt/airflow/data
    command: >
      bash -c "
        airflow db init &&
        airflow users create --username admin --password admin --firstname a --lastname a --role Admin --email admin@example.com
      "

  airflow-webserver:
    image: apache/airflow:2.8.1-python3.10
    depends_on:
      - postgres
      - airflow-init
      - spark
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__FERNET_KEY: ${FERNET_KEY}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: ${AIRFLOW__CORE__SQL_ALCHEMY_CONN}
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./spark_jobs:/opt/airflow/spark_jobs
      - ./data:/opt/airflow/data
    ports:
      - "8080:8080"
    command: airflow webserver

  airflow-scheduler:
    image: apache/airflow:2.8.1-python3.10
    depends_on:
      - postgres
      - airflow-init
      - spark
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__FERNET_KEY: ${FERNET_KEY}
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: ${AIRFLOW__CORE__SQL_ALCHEMY_CONN}
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./spark_jobs:/opt/airflow/spark_jobs
      - ./data:/opt/airflow/data
    command: airflow scheduler

  spark:
    build:
      context: .
      dockerfile: Dockerfile.spark
    volumes:
      - ./spark_jobs:/opt/airflow/spark_jobs
      - ./data:/opt/airflow/data

volumes:
  postgres_data:
